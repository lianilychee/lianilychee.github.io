<html>

<head>

	<title>Liani Lye</title>
	<link rel='shortcut icon' type='../../image/png' href='../../images/favicon.png'>
	<link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
	<link href='http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
	<script src='../../js/jquery.min.js'></script>
	<link rel='stylesheet' href='../../css/style.css' />

</head>

<body>
	<!-- *** NAV BAR *** -->
	<nav>
		<div class='wrapper'>
			<a href='../../index.html' id='nav-title'>L I A N I <font color='#2C85C9'><b>L Y E</b> </font></a><br>

			<div id='nav-menu'>
				<a href='../../index.html' id='aboutlink'> About</a>
				<a href='../../folio.html' id='portfoliolink'> Portfolio</a>
			</div>
		</div>
	</nav>


	<!-- *** SECTIONS *** -->
	<div id='portfolio' class='section-container content'>

		<h1><a href='https://github.com/lianilychee/beatz' target='_blank'>BEATZ</a></h1>

		<p>For the final project in Software Design, a Python-based introduction to programming, two peers and I used OpenCV to create a virtual drumset, pictured below.  To play a drum sound, the user touches its respective box.  By rhythmically tapping on one or multiple boxes, one can create a beat.</p><br>

		<img src='screenshot.png' style='display: block; margin-left: auto; margin-right: auto;'><br>

		<p>I was the OpenCV wrangler, which meant I was responsible for processing the streaming video - tracking the user's hand - in order to trigger each drum's audio.  To do so, I ended up implementing three different methods before arriving at a simple, elegant solution.  To read more about my adventures with color thresholding, contour recognition, and fingertip detection, <a href='https://github.com/lianilychee/beatz/wiki/2.2.-Motion-Detection-and-Image-Processing'>click here.</a>  I ended up detecting pixel change within each drum's box.  If enough pixels changed in the comparison between frame and base case image (captured when the program initializes), the audio is triggered.</p>

		<p>It took multiple weeks to arrive at this solution.  Part of the time was learning the ins and outs of programming and Python (again, this was an introductory software course), but most of the time was spent attempting to fine-tune each hand-tracking method to our needs to no avail.  It turns out that pixel change detection, which has nothing to do with hand tracking itself, was the best solution.</p>

		<p>I had two important takeaways: a) Abstraction! b) More simple = more better.	</p>
		

		<div class='key-points'>
			<h2>Links</h2>

			<p><a href='https://github.com/lianilychee/beatz/' target='_blank'>Github repo</p>

			<p><a href='https://github.com/lianilychee/beatz/wiki' target='_blank'>Project Documentation</a></p>
		</div>


		
	</div>

<script src="//static.getclicky.com/js" type="text/javascript"></script>
<script type="text/javascript">try{ clicky.init(100804052); }catch(e){}</script>
<noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/100804052ns.gif" /></p></noscript>

</body>

</html>